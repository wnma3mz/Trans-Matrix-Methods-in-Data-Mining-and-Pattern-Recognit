第十四章

张量支持向量机人脸识别

即使面部表情、光照、视角等发生变化，人类也非常善于识别面部。开发针对不同条件的鲁棒人脸识别自动程序是一个具有挑战性的研究问题，已使用几种不同的方法进行了研究。主成分分析（即SVD）是一种常用的技术，通常被称为“特征面”[23，88，100]。然而，当所有的照片都是在相似的条件下拍摄的时候，这种方法是最好的，当几个环境因素不同的时候，这种方法也不能很好地发挥作用。还研究了更通用的双线性模型；参见，例如[95]。

最近[102，103，104，105]研究了图像合成的多行分析方法。特别是人脸识别问题，采用张量模型，张量面方法。通过让张量的模式代表不同的观察条件，例如照明或面部表情，与PCA方法相比，可以提高识别算法的精度。

在本章中，我们将描述一种与张量面相关的人脸识别张量方法。由于我们处理的图像通常存储为m×n数组，m和n的顺序为100–500，因此要识别的每个面的计算量相当大。我们将讨论张量SVD（hosvd）如何也可用于降维以减少触发器计数。

14.1张量表示

假设我们有一组NP人员的图像，其中每个图像都是一个mi1×mi2数组，mi1mi2=ni。我们假设图像的列被叠加，这样每一个图像都由RN中的向量表示。进一步假设每个人的面部表情都不同。通常情况下，一个人的ni≥5000，而且通常ni比ne和np大得多。这个

一百六十九

图像集合存储为张量，

A∈RNI×NE×NP.（14.1）

我们分别将不同的模式称为图像模式、表达模式和人模式。

例如，如果我们也有不同照明度、视角等每个人的照片，那么我们可以用更高阶张量来表示图像采集[104]。为了简单起见，这里我们只考虑3模张量的情况。高阶张量的推广是直接的。

例14.1。我们对耶鲁大学人脸数据库中的10人图像进行了预处理，将每幅图像剪切并分解为112×78像素，存储在8736的矢量中。图14.1显示了五幅图像。

​                                                                                               

图14.1.有五种不同表达的人1（来自耶鲁大学面部数据库）。

每个人都有11种不同的表情。

当然，模式的顺序是任意的；为了明确和说明目的，我们假设（14.1）的顺序。然而，为了（某种程度上）强调顺序的任意性，将使用符号×e沿表达式模式将张量乘上矩阵，其他模式也同样如此。

我们现在假设并写出薄软管（见定理8.3和（8.9）），

A=S×I F×E G×P H，（14.2）

其中s∈renep×ne×n p是核心张量，p p f∈rni×nenp有正交柱，g∈rn×n和h∈rn×n是正交的。

例14.2。我们计算了10个人的面部图像张量，每个人有10种不同的表情。奇异值如图14.2所示。表达式和人模式中的10个奇异值都是显著的，这意味着表达式和人之间应该相对容易区分。

根据软管的用途，可以用不同的方式解释软管。我们首先说明这种关系

A=D×E g×P h，

14.1张量表示

   

图14.2.图像模式（左）、表达式模式（右，+）和人员模式（右，圆）中的奇异值。

其中d=s×i f：



我=

e

现在，让我们重述张量矩阵乘法的定义（第8.2节）。对于确定性，我们考虑2-模式，即这里的e-模式，乘法：

.

我们看到，固定表达式参数的一个特定值，也就是说，将j=e0对应于只使用g的e0行。通过在person模式中进行类似的选择，我们得到

a（：，e0，p0）=d×e ge0×p hp0，（14.3）

其中ge0表示g的e0行向量，hp0表示h的p0行向量。我们在下图中说明（14.3）：

A（：，e0，p0）

我们用文字概括如下：

通过将张量d与hp0和ge0在各自的模式下相乘，可以合成e0表达中p0人的图像。因此，人p0的独特特征是行向量hp0，表达e0的独特特征是ge0，通过双线性形式。

D×E G×P H.

例14.3。matlab代码

a=tmul（tmul（d，ue（4，：），2），向上（6，：），3）；

在表达式4中给出第6个人（快乐）；见图14.3。回想一下，函数tmul（a，x，i）将张量a乘以模式i中的矩阵x。

   

图14.3.表情4中的人6（快乐）。

14.2人脸识别

我们现在将考虑如下分类问题：

给定一个未知人的图像，用RNI中的向量表示，确定它代表的NP人中的哪一个，或者确定未知人不在数据库中。

14.2.人脸识别

对于分类，我们将hospd（14.2）写成以下形式：

A=C×P H，C=S×I F×E G.（14.4）

对于一个特殊的表达，我们有

A（：，E，：）=C（：，E，：）×P H.（14.5）

显然，我们可以用矩阵来识别张量a（：，e，：）和c（：，e，：），我们表示ae和ce。因此，对于所有的表达式，我们都有线性关系

ae=ceht，e=1,2，…，ne.（14.6）

注意，相同的（正交）矩阵h出现在所有的ne关系中。使用ht=，可以写入（14.6）的P列

（14.7）

我们可以解释（14.6）和（14.7）如下：

ae的p列包含表达式e中的person p的图像。ce的列是表达式e的基向量，h的p行（即hp）在此基础上保持person p图像的坐标。此外，同一个HP在所有表达式库中保存着人P的图像坐标。

接下来假设z∈rni是一个未知表达的未知人的图像（不在ne中），我们想对它进行分类。我们称Z为测试图像。显然，如果它是表达式e中人p的图像，那么z在这个基础上的坐标等于hp。因此，我们可以通过计算z在所有表达式基中的坐标，并检查每个表达式的z坐标是否与H的任何行的元素重合（或几乎重合），来对z进行分类。

通过求解最小二乘问题，可以求出表达式基e中z的坐标。

（14.8）

算法总结如下：

​             

### 分类算法（初版）

| %Z是一个测试图像。对于e=1,2，…，ne   求解最小值 | .                             |
| ----------------------------------------------- | ----------------------------- |
| 对于p=1,2，…，np   如果   结束                  | 托尔，然后归类为P人，停下来。 |

该算法的工作量很大：对于每个测试图像z，我们必须用ce∈rni×np求解ne最小二乘问题（14.8）。

然而，从（14.4）中回忆，c=s×i f×e g，这意味着

ce=fbe，

其中bi e∈e prnenp×np是用（s×e g）（：，e，：）标识的矩阵。注意f∈rn×n n；我们假设ni比nenp大得多。然后，仅用于分析，放大矩阵，使其变为方形和正交：

   

现在在标准中插入f_t：

   

因此，我们可以先计算ftz，然后求解ne最小二乘问题。

（14.9）

矩阵be的维数为nenp×np，因此求解（14.9）比（14.8）便宜得多。也可以预先计算每个矩阵的QR分解，以进一步减少工作量。因此，我们得出了以下算法。

​             

### 分类算法

​             

预处理步骤。计算并保存所有be矩阵的qr分解，be=qere，e=1,2，…，ne。

%Z是一个测试图像。

计算_z=ftz。对于e=1,2，…，ne

求αe的reαe=qte z_。

对于p=1,2，…，np

如果是TOL，则归类为P人并停止。

### 结束

​             

14.3.带软管压缩的人脸识别

在一个典型的应用程序中，即使测试图像是数据库中某个人的图像，也可能使用另一个未在数据库中表示的表达式来获取。然而，上述算法在这种情况下工作良好，如[104]所述。

例14.4.在耶鲁大学的数据库中，每10个人都有一个眨眼的图像。我们将这些图像作为测试图像，并使用上面的算法计算出数据库中最接近的图像。在任何情况下

   

图14.4.上面一行显示要分类的图像，下面一行显示数据库中对应的最近的图像。

14.3带软管压缩的人脸识别

由于堆芯的有序性，对于不同的模式（定理8.3），我们可以截断堆芯，这样截断的hospd仍然是A的一个很好的近似值。对于我们假设的一些k值，定义fk=f（：，1:k），它比ni小得多，但比ni大得多。比NP。然后，仅用于分析，放大矩阵，使其变为方形和正交：

   

然后类似地截断核心张量，即

（14.10）

由定理8.3可知，E-模中G的乘法不影响I-模中的hospd排序性质。

.

因此，如果图像模式奇异值的衰减速度足够快，则尽管存在压缩，但仍有可能获得良好的识别精度。因此，如果我们在前面的算法中使用c，我们将不得不解决最小二乘问题。

   

具有明显的定义。现在，从（14.10）开始，我们在哪里。在范数符号内乘我们得到的

.

在识别算法的“压缩”变体中，操作_z=ftz替换为_，并且循环中的最小二乘问题是

更小。

例14.5。我们使用了与前一个示例相同的数据，但在图像模式中将正交基截断为k。当k=10时，所有测试图像都被正确分类，但当k=5时，10个图像中的2个被错误分类。因此，在本例中，在不牺牲分类精度的情况下，可以大幅降低等级（从100降到10）。

在我们的示例中，人数和不同的表达式太少，不需要进一步压缩数据。然而，在实际应用中，为了在合理的时间内对图像进行分类，可以在表达式和人称模式中截断核心张量，从而解决比未压缩情况下更小的最小二乘问题。


 

第三部分

计算矩阵

分解


 