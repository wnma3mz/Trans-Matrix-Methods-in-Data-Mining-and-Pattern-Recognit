# 第三章 线性系统和最小二乘

在本章中，我们简要回顾了关于线性方程组解的一些事实，

$A x = b$，式3.1

式中 $A \in \mathbb { R } ^ { n \times n }$ 为方阵且非奇异。线性系统（3.1）可以用*高斯消元*和*部分旋转*来求解，这相当于将矩阵分解为三角矩阵的乘积。

我们还将考虑*超定线性方程组*，其中矩阵 $A \in \mathbb { R } ^ { m \times n }$ 是 $m>n$ 的*矩形*，并使用最小二乘法求解。因为我们只提供结果作为前提，所以我们大多是在没有证明的情况下陈述结果。有关求解线性方程组的矩阵分解理论的详细介绍，请参见，如[42，92]。

在讨论矩阵分解之前，我们陈述了关于（3.1）唯一解存在条件的基本结果。

**命题 3.1.** *设 $A \in \mathbb { R } ^ { n \times n }$ ，假设 $A$ 是非奇异的。然后对于任何右手边 $b$，线性方程组 $Ax=b$ 有一个唯一的解。*

**证明**。结果是非奇异矩阵的列向量线性无关的直接结果。

## 3.1 LU分解

利用*高斯变换*可以方便地描述高斯消元，这些变换是高斯消元与LU分解等价的关键。关于高斯变换的更多细节可以在任何一本线性代数教科书中找到；参见，如[42，94页]。在部分旋转的高斯消元中，行的重新排序是通过*置换矩阵*，是具有重新排序行的单位矩阵；参见，例如[42，第3.4.1节]。

考虑一个 $n\times n$ 矩阵 $A$。在部分旋转高斯消元的第一步中，我们重新排列矩阵的行，以便将第一列中最大数量的元素移动到（1,1）位置。这相当于将 $A$ 从左侧乘以置换矩阵 $P_1$。然后用相乘的方法进行消除，即在对角线下方第一列中元素的归零。

$A ^ { ( 1 ) } : = L _ { 1 } ^ { - 1 } P _ { 1 } A$，式3.2

其中，$L_1$ 是高斯变换

$L _ { 1 } = \left( \begin{array} { c c } { 1 } & { 0 } \\ { m _ { 1 } } & { I } \end{array} \right) , \quad m _ { 1 } = \left( \begin{array} { c } { m _ { 21 } } \\ { m _ { 31 } } \\ { \vdots } \\ { m _ { n 1 } } \end{array} \right)$

部分旋转高斯消元第一步的结果是

$A ^ { ( 1 ) } = \left( \begin{array} { c c c c } { a _ { 11 } ^ { \prime } } & { a _ { 12 } ^ { \prime } } & { \dots } & { a _ { 1 n } ^ { \prime } } \\ { 0 } & { a _ { 22 } ^ { ( 1 ) } } & { \cdots } & { a _ { 2 n } ^ { ( 1 ) } } \\ { \vdots } & { } & { } \\ { 0 } & { a _ { n 2 } ^ { ( 1 ) } } & { \dots } & { a _ { n n } ^ { ( 1 ) } } \end{array} \right)$

然后，高斯消除算法通过将第二列的元素归零（将最大的元素移动到对角线位置之后），依此类推。

从（3.2）我们可以看出，带有部分旋转的高斯消元的第一步可以表示为矩阵分解。整个过程也是如此。

**定理3.2（LU分解）**。*任何非奇异的 $n×n$ 矩阵 $A$ 都可以分解为*

$P A = L U$

其中 $P$ 是置换矩阵，$L$ 是下三角矩阵，主对角线上有一个矩阵，$U$ 是上三角矩阵。

**证明**（草图）。这个定理可以用归纳法证明。从（3.2）可以得到

$P _ { 1 } A = L _ { 1 } A ^ { ( 1 ) }$

定义 $（n-1）×（n-1）$ 矩阵

$B = \left( \begin{array} { c c c } { a _ { 22 } ^ { ( 1 ) } } & { \dots } & { a _ { 2 n } ^ { ( 1 ) } } \\ { \vdots } & { } & { } \\ { a _ { n 2 } ^ { ( 1 ) } } & { \cdots } & { a _ { n n } ^ { ( 1 ) } } \end{array} \right)$

通过归纳假设，$B$ 可以分解为

$P _ { B } B = L _ { B } U _ { B }$

然后我们看到，$P A = L U$，其中

$U = \left( \begin{array} { c c } { a _ { 11 } ^ { \prime } } & { a _ { 2 } ^ { T } } \\ { 0 } & { U _ { B } } \end{array} \right) , \quad L = \left( \begin{array} { c c } { 1 } & { 0 } \\ { P _ { B } m _ { 1 } } & { L _ { B } } \end{array} \right) , \quad P = \left( \begin{array} { c c } { 1 } & { 0 } \\ { 0 } & { P _ { B } } \end{array} \right) P _ { 1 }$

和$a _ { 2 } ^ { T } = \left( a _ { 12 } ^ { \prime } a _ { 13 } ^ { \prime } \ldots a _ { 1 n } ^ { \prime } \right)$

很容易证明计算 $\rm LU$ 分解的工作量大约是 $2n^3/3$ 次。在高斯消元的第$k$步中，一个操作在 $（n−k+1）×（n−k+1）$ 子矩阵上，对于该子矩阵中的每个元素，执行一次乘法和一次加法。因此，总的计算次数

$2 \sum\limits_ { k = 1 } ^ { n - 1 } ( n - k + 1 ) ^ { 2 } \approx \frac { 2 n ^ { 3 } } { 3 }$

## 3.2 对称正定矩阵

对称正定矩阵 $A$ 的 $\rm LU$ 分解总是可以不用旋转来计算。此外，可以利用对称性，使分解也变得对称，并且需要的工作量是一般情况下的一半。

**定理3.3（$LDL^T$ 分解）** *任何对称正定矩阵 $A$ 都有分解*

$A = L D L ^ { T }$

其中，$L$ 是下三角形，主对角线上有一个，$D$ 是一个对角矩阵，带有正对角元素。

**例3.4.** 正定矩阵

$A = \left( \begin{array} { l l l } { 8 } & { 4 } & { 2 } \\ { 4 } & { 6 } & { 0 } \\ { 2 } & { 0 } & { 3 } \end{array} \right)$                                       

有 $\rm LU$ 分解

$A = L U = \left(\begin{array} { c c c } { 1 } & { 0 } & { 0 } \\ { 0.5 } & { 1 } & { 0 } \\ { 0.25 } & { -0.25 } & { 1 } \end{array} \right) \left(\begin{array} { c c c } { 8 } & { 4 } & { 2 } \\ { 0 } & { 4 } & { -1 } \\ { 0 } & { 0 } & { 2.25 } \end{array} \right)$

与 $\rm LDL^T$ 分解

$A = L D L ^ { T } , \quad D = \left(\begin{array} { c c c } { 8 } & { 0 } & { 0 } \\ { 0 } & { 4 } & { 0 } \\ { 0 } & { 0 } & { 2.25 } \end{array} \right)$

$D$ 中的对角线元素是正的，因此我们可以把

$D ^ { 1 / 2 } = \left( \begin{array} { c c c c } { \sqrt { d _ { 1 } } } & { } & { } & { } \\ { } & { \sqrt { d _ { 2 } } } & { } & { } \\ { } & { } & { \ddots } & { } \\ { } & { } & { } & { \sqrt { d _ { n } } } \end{array} \right)$

然后我们得到

$A = L D L ^ { T } = \left( L D ^ { 1 / 2 } \right) \left( D ^ { 1 / 2 } L ^ { T } \right) = U ^ { T } U$

其中 $U$ 是上三角矩阵。这种 $LDL^T$ 分解的变体称为*Cholesky分解*。

由于 $A$ 是对称的，所以只需要存储主对角线及其上的元素，即 $n（n+1）/2$ 个矩阵元素。$LDL^T$ 和Cholesky分解所需的存储量完全相同。也可以看出，由于只需要计算普通 $\rm LU$ 分解中一半的元素，因此工作量也减半，大约为 $n^3/3$ 次。当计算$LDL^T$分解时，不需要首先计算 $\rm LU$ 分解，但是可以直接计算 $L$ 和 $D$ 中的元素。

## 3.3 微扰理论和条件数

非奇异矩阵 $A$ 的*条件数*定义为

$\kappa ( A ) = \| A \| \left\| A ^ { - 1 } \right\|$

其中 $||\cdot||$ 表示任何算子范数。如果我们使用一个特殊的矩阵范数，例如二次范数，那么我们就写成

$\kappa _ { 2 } ( A ) = \| A \| _ { 2 } \left\| A ^ { - 1 } \right\| _ { 2 }$，式3.3

当矩阵和右侧受到少量扰动时，条件数用于量化线性系统 $Ax = b$ 的解可以改变多少

**定理3.5** *假设 $A$ 是非奇异的*

$\| \delta A \| \left\| A ^ { - 1 } \right\| = r < 1$

*那么矩阵 $A + \delta A$ 是非奇异的，并且*

$\left\| ( A + \delta A ) ^ { - 1 } \right\| \leq \frac { \left\| A ^ { - 1 } \right\| } { 1 - r }$

*扰动系统的解为*

$( A + \delta A ) y = b + \delta b$

*满足*

$\frac { \| y - x \| } { \| x \| } \leq \frac { \kappa ( A ) } { 1 - r } \left( \frac { \| \delta A \| } { \| A \| } + \frac { \| \delta b \| } { \| b \| } \right)$

例如，有关证明，请参见[42，定理2.7.2]或[50，定理7.2]

条件数较大的矩阵称为*病态矩阵*。定理3.5表明，具有病态矩阵的线性方程组对数据中的扰动（即矩阵和右手边）敏感。

## 3.4 高斯消去中的舍入误差

从第1.5.2节，关于浮点运算中的舍入误差，我们知道任何实数（在浮点系统中可表示）都用不超过单位舍入 $\mu$ 的相对误差表示。这个事实也可以说

$f l [ x ] = x ( 1 + \epsilon ) , \quad | \epsilon | \leq \mu$

当在浮点系统中表示矩阵 $A$ 和向量 $b$ 的元素时，会出现错误：

$f l \left[ a _ { i j } \right] = a _ { i j } \left( 1 + \epsilon _ { i j } \right) , \quad \left| \epsilon _ { i j } \right| \leq \mu$

类似于b。因此，我们可以写成

$f l [ A ] = A + \delta A , \quad f l [ b ] = b + \delta b$

其中

$\| \delta A \| _ { \infty } \leq \mu \| A \| _ { \infty } , \quad \| \delta b \| _ { \infty } \leq \mu \| b \| _ { \infty }$

如果，目前我们假设在求解方程组 $Ax = b$ 过程中没有出现进一步的舍入误差，我们看到了吗？ $\widehat { x }$ 满足

$( A + \delta A ) \widehat { x } = b + \delta b$

这是*反向误差分析*的一个例子：计算出的解 $\widehat { x }$ 是*精确的扰动问题的解*

利用微扰理论，我们可以从定理3.5中估计 $\widehat { x }$ 的误差。

$\frac { \| \widehat { x } - x \| _ { \infty } } { \| x \| _ { \infty } } \leq \frac { \kappa _ { \infty } ( A ) } { 1 - r } 2 \mu$

（如果 $r = \mu \kappa _ { \infty } ( A ) < 1$）

我们还可以分析高斯消元中的舍入误差对结果的影响。以下定理成立。（有关高斯消元的详细误差分析，请参阅[50，第9章]或[42，第3.3、3.4章]。）

**定理3.6** *假设我们使用单位舍入 $\mu$ 的浮点系统。$L$ 和 $R$是从高斯消去得到具有部分旋转的三角形因子，应用于矩阵 $A$。此外，假设 $\widehat { x }$ 是用前向和后向替换计算：*

$\widehat { L } \widehat { y } = P b , \quad \widehat { R } \widehat { x } = \widehat { y }$

*然后 $\widehat { x }$ 是系统的精确解*

$( A + \delta A ) \widehat { x } = b$

*其中*

$\| \delta A \| _ { \infty } \leq k ( n ) g _ { n } \mu \| A \| _ { \infty } , \quad g _ { n } = \frac { \max _ { i , j , k } \left| \widehat { a } _ { i j } ^ { ( k ) } \right| } { \max _ { i , j } \left| a _ { i j } \right| }$

*$k(n)$ 是 $n$ 中一个三次多项式，$\widehat { a } _ { i j } ^ { ( k ) }$ 是在消除过程的步骤 $k-1$ 中计算出的元素。*

我们观察到 $g_n$ 依赖于高斯消去过程中矩阵元素的增长，而不是明确依赖于乘数的大小。可以计算 $g_n$，这样就可以得到舍入误差的后验估计。

*先验*（预先），我们可以证明 $g_n \leq 2^{n−1}$，并且可以在元素增长如此猛烈的地方构建矩阵（注意，$g_{31}=2^{30}\approx 10^9$ ）。然而，在实际中，高斯消元部分旋转时，$g_n$ 很少大于8。

重要的是要注意，在高斯消去过程中，有些矩阵类没有元素增长，即 $g_n=1$，即使没有进行旋转。这是真的，例如，如果 $A$ 是对称的和正定的。

在几乎所有的情况下，定理中的估计对于三次多项式 $k(n)$ 都过于悲观。为了具有相等性，所有舍入误差必须最大化，且其累积效应必须最大化的不利。

我们要强调的是，这种先验误差分析的主要目的不是给出线性方程组解的误差估计，而是揭示算法的潜在不稳定性，并为比较不同算法提供依据。因此，定理3.6证明了高斯变换与我们将在第4章中介绍的正交变换相比的主要弱点：它们会导致矩阵元素的大增长，进而导致舍入误差。

## 3.5 带状矩阵

在许多情况下，例如，常微分方程和偏微分方程的边值问题，当大部分元素等于零时，就会出现矩阵。如果非零元素集中在主对角线周围，则该矩阵称为带状矩阵。更准确地说，如果存在自然数 $p$ 和 $q$，那么矩阵 $A$ 被称为*带状矩阵*。

$a _ { i j } = 0 \text { if } j - i > p \text { or } i - j > q$

**例3.7.** 设 $q=2，p=1$。设 $A$ 为维度6的带状矩阵：

$A = \left( \begin{array} { c c c c c c } { a _ { 11 } } & { a _ { 12 } } & { 0 } & { 0 } & { 0 } & { 0 } \\ { a _ { 21 } } & { a _ { 22 } } & { a _ { 23 } } & { 0 } & { 0 } & { 0 } \\ { a _ { 31 } } & { a _ { 32 } } & { a _ { 33 } } & { a _ { 34 } } & { 0 } & { 0 } \\ { 0 } & { a _ { 42 } } & { a _ { 43 } } & { a _ { 44 } } & { a _ { 45 } } & { 0 } \\ { 0 } & { 0 } & { a _ { 53 } } & { a _ { 54 } } & { a _ { 55 } } & { a _ { 56 } } \\ { 0 } & { 0 } & { 0 } & { a _ { 64 } } & { a _ { 65 } } & { a _ { 66 } } \end{array} \right)$

$w=q+p+1$ 被称为矩阵的*带宽*。从这个例子来看，我们看到 $w$ 是 $A$ 中任何一行中非零元素的最大数目。

存储带矩阵时，我们不存储带外的元素。同样，当线性方程组求解时，可以利用带结构来减少运算次数。

我们首先考虑 $p=q=1$ 的情况。这样的带矩阵称为*三对角矩阵*。令

$A = \left( \begin{array} { c c c c c c } { \alpha _ { 1 } } & { \beta _ { 1 } } & { } & { } & { } \\ { \gamma _ { 2 } } & { \alpha _ { 2 } } & { \beta _ { 2 } } & { } & { } \\ { } & { \gamma _ { 3 } } & { \alpha _ { 3 } } & { \beta _ { 3 } } \\ { } & { } & { } & { } \\ { } & { } & { \ddots } & { \ddots } & { \ddots } \\ { } & { } & { } & { \gamma _ { n - 1 } } & { \alpha _ { n - 1 } } & { \beta _ { n - 1 } } \\ { } & { } & { } & { \gamma _ { n } } & { } & { \alpha _ { n } } \end{array} \right)$

矩阵可以存储在三个向量中。在一个三对角系统 $Ax=b$ 的解中，很容易利用这个结构；我们首先假设 $A$ 是对角占优的，因此不需要旋转。

```matlab
% LU Decomposition of a Tridiagonal Matrix.
for k=1:n-1
  gamma(k+1)=gamma(k+1)/alpha(k);
  alpha(k+1)=alpha(k+1)*beta(k);
end
% Forward Substitution for the Solution of Ly = b.
y(1)=b(1);
for k=2:n
  y(k)=b(k)-gamma(k)*y(k-1);
end
% Back Substitution for the Solution of Ux = y.
x(n)=y(n)/alpha(n);
for k=n-1:-1:1
  x(k)=(y(k)-beta(k)*x(k+1))/alpha(k);
end
```

运算（乘法和加法）的次数约为 $3n$，除法的次数为 $2n$。

在*部分旋转*高斯消元中，上三角矩阵的带宽增大。如果 $A$ 的带宽 $w=q+p+1$（主对角线下的 $q$ 对角线和 $p$ 上），那么在部分旋转的情况下，系数 $\mu$ 的带宽 $w_U=p+q+1$。很容易看出，在 $L$ 中不会创建新的非零元素。

带矩阵 $A$ 的 $LU$ 分解中的因子 $L$ 和 $U$ 是带状矩阵。

**例3.8** 让

$A = \left( \begin{array} { c c c c c } { 4 } & { 2 } & { } & { } & { } \\ { 2 } & { 5 } & { 2 } & { } & { } \\ { } & { 2 } & { 5 } & { 2 } & { } \\ { } & { } & { 2 } & { 5 } & { 2 } \\ { } & { } & { } & { 2 } & { 5 } \end{array} \right)$

$A$ 具有Cholesky分解 $A=U^TU$，其中

$U = \left( \begin{array} { c c c c c } { 2 } & { 1 } & { } & { } & { } \\ { } & { 2 } & { 1 } & { } & { } \\ { } & { } & { 2 } & { 1 } & { } \\ { } & { } & { } & { 2 } & { 1 } \\ { } & { } & { } & { } & { 2 } \end{array} \right)$

逆矩阵为

$A ^ { - 1 } = \frac { 1 } { 2 ^ { 10 } } \left( \begin{array} { c c c c c } { 341 } & { - 170 } & { 84 } & { - 40 } & { 16 } \\ { - 170 } & { 340 } & { - 168 } & { 80 } & { - 32 } \\ { 84 } & { - 168 } & { 336 } & { - 160 } & { 64 } \\ { - 40 } & { 80 } & { - 160 } & { 320 } & { - 128 } \\ { 16 } & { - 32 } & { 64 } & { - 128 } & { 256 } \end{array} \right)$

稠密矩阵

结果表明，带矩阵的逆矩阵通常是稠密矩阵。因此，在大多数情况下，不应显式计算带矩阵的逆矩阵。

## 3.6 最小二乘问题

在这一节中，我们将介绍最小二乘法和使用正规方程的线性最小二乘问题的解。基于正交变换的最小二乘问题的其他解决方法将在第5章和第6章中介绍。我们还将给出第6.6节中最小二乘问题的扰动结果。有关线性最小二乘问题的现代数值方法的广泛处理，请参见[14]。

**例3.9** 假设我们想通过附加不同的重量和测量弹簧的长度来确定弹簧的弹性特性。根据胡克定律，我们知道长度 $l$ 取决于力 $F$，根据

$e + \kappa F = l$

其中 $e$ 和 $\kappa$ 是常数$^5$，有待确定。假设我们进行了一项实验，并获得了以下数据：

|  F   |  1   |  2   |  3   |  4   |  5   |
| :--: | :--: | :--: | :--: | :--: | :--: |
|  1   | 7.97 | 10.2 | 14.2 | 16.0 | 21.1 |

数据如图3.1所示。由于测量值存在误差，我们希望使用所有数据，以尽量减少误差的影响。因此，我们得到了一个比未知数据更多的方程组，一个超定方程组，

$\begin{array} { l } { e + \kappa 1 = 7.97 } \\ { e + \kappa 2 = 10.2 } \\ { e + \kappa 3 = 14.2 } \\ { e + \kappa 4 = 16.0 } \\ { e + \kappa 5 = 21.2 } \end{array}$

或者，以矩阵形式，

$\left(\begin{array} { l l } { 1 } & { 1 } \\ { 1 } & { 2 } \\ { 1 } & { 3 } \\ { 1 } & { 4 } \\ { 1 } & { 5 } \end{array} \right) \left(\begin{array} { l } { e } \\ { \kappa } \end{array} \right) = \left(\begin{array} { c } { 7.97 } \\ { 10.2 } \\ { 14.2 } \\ { 16.0 } \\ { 21.2 } \end{array} \right)$

我们将用最小二乘法确定弹簧弹性常数的近似值。

$^5$ 在胡克定律中，弹簧常数为 $1 / \kappa$。

图3.1 *弹簧试验中的测量数据*

![](imgs\Fig3.1.png)设a∈rm×n，m>n，系统

设 $A \in \mathbb { R } ^ { m \times n } , m > n$。方程组为

$ Ax=b $

被称为*超定*：它有比未知更多的方程。一般来说，这样的方程组无解。这可以通过让 $m=3$ 和 $n=2$ 从几何上看，也就是说，我们考虑了 $\mathbb { R }^3$ 中的两个向量 $a_{\cdot 1}$ 和 $a_{\cdot 2}$。我们想找到向量的线性组合，这样

$x _ { 1 } a _ { \cdot 1 } + x _ { 2 } a _ { \cdot 2 } = b$

在图3.2中，我们看到通常这样的问题无解。这两个向量跨越一个平面，如果右侧 $b$ 不在平面内，则 $a_{\cdot 1}$ 和 $a_{\cdot 2}$没有线性组合，因此 $x _ { 1 } a _ { \cdot 1 } + x _ { 2 } a _ { \cdot 2 } = b$。

在这种情况下，“求解线性方程组”的一个明显的替代方法是使向量 $r = b - x _ { 1 } a _ { 1 } - x _ { 2 } a _ { \cdot 2 } = b - A x$ 尽可能小。 $b-Ax$ 称为*剩余向量*，如图3.2所示。

问题的求解取决于我们如何测量剩余向量的长度。在*最小二乘法*中，我们使用标准欧几里得距离。因此，我们要找到一个向量 $x\in \mathbb{R}^n$ 来解决最小化问题。

$\min\limits_ { x } \| b - A x \| _ { 2 }$，式3.4

**图3.2** *最小二乘问题，$m=3，n=2$。剩余向量 $b- Ax$ 是点。*

![](imgs\Fig3.2.png)

由于未知 $x$ 在（3.4）中呈线性出现，这也被称为*线性最小二乘问题*。

在这个例子中，我们从我们在 $\mathbb{R}^3$ 中的距离的知识中立即知道，如果我们选择平面中向量的线性组合，使得剩余矢量与平面正交，则向量 $b$ 的尖端与平面之间的距离最小化。由于矩阵 $A$ 的列跨越了平面，因此我们通过使 *$r$ 与 $A$ 的列正交*。这种几何直觉在一般情况下也是有效的：

$r ^ { T } a _ { \cdot j } = 0 , \quad j = 1,2 , \ldots , n$

（见第2.3节中正交性的定义）同样，我们可以

$r ^ { T } \left(\begin{array} { c c c c } { a _{ .1 } } & { a _{ .2 } } & { \cdots } & { a _{ . n } } \end{array} \right) = r ^ { T } A = 0$

然后，使用 $r=b−Ax$ ，我们得到了*正态方程*（命名很直接）

$A ^ { T } A x = A ^ { T } b$

用于确定 $x$ 中的系数。

**定理3.10** *如果 $A$ 的列向量是线性无关的，则法向方程*

$A ^ { T } A x = A ^ { T } b$

*是非奇异的，有一个唯一的解。*

**证明** 我们首先证明了 $A^TA$ 是正定的。设 $x$ 为任意非零矢量。然后，从线性无关的定义来看，我们得到 $Ax\ne 0$。当 $y=Ax$ 时，我们有

$x ^ { T } A ^ { T } A x = y ^ { T } y = \sum\limits_ { i = 1 } ^ { n } y _ { i } ^ { 2 } > 0$

相当于 $A^TA$ 是正定的。因此， $A^TA$ 是非奇异的，正态方程有一个唯一的解，我们表示 $\widehat { x }$

然后，我们证明 $\widehat{x}$ 是最小二乘问题的解，即 $||\widehat{r}||_2\leq ||r||_2$，对于所有的 $r = b - A x$，可以写作

$ r = b - A \widehat { x } + A ( \widehat { x } - x ) = \widehat { r } + A ( \widehat { x } - x )$

与

$\begin{aligned} \| r \| _ { 2 } ^ { 2 } & = r ^ { T } r = ( \widehat { r } + A ( \widehat { x } - x ) ) ^ { T } ( \widehat { r } + A ( \widehat { x } - x ) ) \\ & = \widehat { r } ^ { T } \widehat { r } + \widehat { r } ^ { T } A ( \widehat { x } - x ) + ( \widehat { x } - x ) ^ { T } A ^ { T } \widehat { r } + ( \widehat { x } - x ) ^ { T } A ^ { T } A ( \widehat { x } - x ) \end{aligned}$

因为 $A ^ { T } \widehat { r } = 0$，中间两项为0，于是可得

$\| r \| _ { 2 } ^ { 2 } = \widehat { r } ^ { T } \widehat { r } + ( \widehat { x } - x ) ^ { T } A ^ { T } A ( \widehat { x } - x ) = \| \widehat { r } \| _ { 2 } ^ { 2 } + \| A ( \widehat { x } - x ) \| _ { 2 } ^ { 2 } \geq \| \widehat { r } \| _ { 2 } ^ { 2 }$

这是需要证明的。

**例3.11** 我们现在可以解决本章开头给出的示例。我们有

$A = \left(\begin{array} { c c c } { 1 } & { 1 } & { 1 } \\ { 1 } & { 2 } \\ { 1 } & { 3 } \\ { 1 } & { 41 } & { 5 } \end{array} \right) , \quad b = \left(\begin{array} { c } { 7.97 } \\ { 10.2 } \\ { 14.2 } \\ { 16.021 .2 } \end{array} \right)$

然后使用MATLAB得到

```matlab
>> C=A’*A % Normal equations

C = 5 15
    15 55
    
>> x=C\(A’*b)

x = 4.2360
    3.2260
```

使用法向方程求解线性最小二乘问题有两个显著缺点：

1. 形成 $A^TA$ 会导致信息丢失。

2. 条件数 $A^TA$ 是 $A$ 的平方：

   $\kappa\left(A^{T} A\right)=(\kappa(A))^{2}$

我们用几个例子来说明这些要点。

**例3.12** 设为 $\epsilon$ 小，并定义矩阵

$A=\left(\begin{array}{ll}{1} & {1} \\ {\epsilon} & {0} \\ {0} & {\epsilon}\end{array}\right)$

接下来是

$A^{T} A=\left(\begin{array}{cc}{1+\epsilon^{2}} & {1} \\ {1} & {1+\epsilon^{2}}\end{array}\right)$

如果 $\epsilon$  非常小，$1+\epsilon^{2}$ 的浮点表示满足 $f l\left[1+\epsilon^{2}\right]=1$ ，则在浮点运算中，法方程变为奇异方程。因此，在形成 $A^TA$ 时会丢失 $A$ 中存在的重要信息。

使用 $A$ 的奇异值分解定义了矩形矩阵 $A$ 的条件数。我们将在第6.6节中陈述关于最小二乘问题条件的结果。

**例3.13** 我们使用matlab计算例3.9中矩阵的条件数：

```matlab
A = 1 1
    1 2
    1 3
    1 4
    1 5
    
cond(A) = 8.3657

cond(A’*A) = 69.9857
```

然后我们假设我们有一个线性模型

$l(x)=c_{0}+c_{1} x$

对于数据向量 $x=(101 \quad 102 \quad 103 \quad 104 \quad 105)^{T}$。这给出了一个大条件数的数据矩阵：

```matlab
A = 1 101
    1 102
    1 103
    1 104
    1 105
    
cond(A) = 7.5038e+03

cond(A’*A) = 5.6307e+07
```

如果我们使用该模型

$l(x)=b_{0}+b_{1}(x-103)$

相应的法向方程变成对角线，并且条件更好（证明这一点）。

经常会出现一个矩阵相同的最小二乘问题序列，

$\min _{x_{i}}\left\|A x_{i}-b_{i}\right\|_{2}, \quad i=1,2, \ldots, p$

其解为

$x_i=(A^TA)^{-1}A^Tb_i, \quad i=1,2, \ldots, p$

定义 $X=\left(\begin{array}{llll}{x_{1}} & {x_{2}} & {\dots} & {x_{p}}\end{array}\right)$ 与 $X=\left(\begin{array}{llll}{b_{1}} & {b_{2}} & {\ldots} & {b_{p}}\end{array}\right)$，之后我们可以用矩阵形式写成

$\min _{X}\|A X-B\|_{F}$，式3.5

这个解为

$X=\left(A^{T} A\right)^{-1} A^{T} B$

这单位矩阵如下形式

$\|A X-B\|_{F}^{2}=\sum_{i=1}^{p}\left\|A x_{i}-b_{i}\right\|_{2}^{2}$

以及（3.5）中的 $p$ 子问题是独立的。